{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "      id      cuisine                                        ingredients\n",
      "0  10259        greek  romaine lettuce,black olives,grape tomatoes,ga...\n",
      "1  25693  southern_us  plain flour,ground pepper,salt,tomatoes,ground...\n",
      "2  20130     filipino  eggs,pepper,salt,mayonaise,cooking oil,green c...\n",
      "3  22213       indian                     water,vegetable oil,wheat,salt\n",
      "4  13162       indian  black pepper,shallots,cornflour,cayenne pepper...\n",
      "\n",
      "Test Data:\n",
      "      id                                        ingredients\n",
      "0  18009  baking powder,eggs,all-purpose flour,raisins,m...\n",
      "1  28583  sugar,egg yolks,corn starch,cream of tartar,ba...\n",
      "2  41580  sausage links,fennel bulb,fronds,olive oil,cub...\n",
      "3  29752  meat cuts,file powder,smoked sausage,okra,shri...\n",
      "4  35687  ground black pepper,salt,sausage casings,leeks...\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data:\")\n",
    "print(train.head())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data Columns: Index(['id', 'cuisine', 'ingredients'], dtype='object')\n",
      "Test Data Columns: Index(['id', 'ingredients'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain Data Columns:\", train.columns)\n",
    "print(\"Test Data Columns:\", test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Data\n",
    "#### Data Cleaning: Handle missing values.\n",
    "#### Feature Extraction: Convert ingredients into a numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train data:\n",
      " id             0\n",
      "cuisine        0\n",
      "ingredients    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data:\n",
      " id             0\n",
      "ingredients    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in train data:\\n\", train.isnull().sum())\n",
    "print(\"\\nMissing values in test data:\\n\", test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values if any\n",
    "\n",
    "train.fillna('', inplace=True)\n",
    "test.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['all_ingredients'] = train['ingredients'].apply(lambda x: ' '.join(x.split(',')))\n",
    "test['all_ingredients'] = test['ingredients'].apply(lambda x: ' '.join(x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 2970)\n",
      "(9944, 2970)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert ingredients into TF-IDF features\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(train['all_ingredients'])\n",
    "X_test_tfidf = tfidf.transform(test['all_ingredients'])\n",
    "\n",
    "print(X_train_tfidf.shape)\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# combined_ingredients = pd.concat([train_df['ingredients'], test_df['ingredients']])\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# tfidf_matrix = vectorizer.fit_transform(combined_ingredients)\n",
    "\n",
    "# tfidf_train = tfidf_matrix[:len(train_df)]\n",
    "# tfidf_test = tfidf_matrix[len(train_df):]\n",
    "\n",
    "# if 'dietary_restrictions' in train_df.columns:\n",
    "#     train_df = pd.get_dummies(train_df, columns=['dietary_restrictions'])\n",
    "# if 'dietary_restrictions' in test_df.columns:\n",
    "#     test_df = pd.get_dummies(test_df, columns=['dietary_restrictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the Recommendation System\n",
    "\n",
    "\n",
    "#### Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id      cuisine                                        ingredients  \\\n",
      "0  10259        greek  romaine lettuce,black olives,grape tomatoes,ga...   \n",
      "1  25693  southern_us  plain flour,ground pepper,salt,tomatoes,ground...   \n",
      "2  20130     filipino  eggs,pepper,salt,mayonaise,cooking oil,green c...   \n",
      "3  22213       indian                     water,vegetable oil,wheat,salt   \n",
      "4  13162       indian  black pepper,shallots,cornflour,cayenne pepper...   \n",
      "\n",
      "                                     all_ingredients  \n",
      "0  romaine lettuce black olives grape tomatoes ga...  \n",
      "1  plain flour ground pepper salt tomatoes ground...  \n",
      "2  eggs pepper salt mayonaise cooking oil green c...  \n",
      "3                     water vegetable oil wheat salt  \n",
      "4  black pepper shallots cornflour cayenne pepper...  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-based collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47823 16886 20604 41720  6436]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "user_ratings = pd.DataFrame(np.random.randint(1, 6, size=(100, len(train))), columns=train['id'])\n",
    "\n",
    "def collaborative_filtering(user_id, user_ratings, n_recommendations=5):\n",
    "    user_similarity = cosine_similarity(user_ratings)\n",
    "    similar_users = user_similarity[user_id].argsort()[:-n_recommendations-1:-1]\n",
    "    recommendations = user_ratings.iloc[similar_users].mean().sort_values(ascending=False)\n",
    "    return recommendations.index.values[:n_recommendations]\n",
    "\n",
    "print(collaborative_filtering(0, user_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0 34089 16419 37955 32784]\n"
     ]
    }
   ],
   "source": [
    "def content_based_recommendations(recipe_id, X_tfidf, n_recommendations=5):\n",
    "    cosine_similarities = cosine_similarity(X_tfidf[recipe_id], X_tfidf).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-n_recommendations-1:-1]\n",
    "    return related_docs_indices\n",
    "\n",
    "print(content_based_recommendations(0, X_train_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 0 1 3]\n"
     ]
    }
   ],
   "source": [
    "def hybrid_recommendations(user_id, recipe_id, X_tfidf, user_ratings, n_recommendations=5):\n",
    "    content_recommendations = content_based_recommendations(recipe_id, X_tfidf, n_recommendations)\n",
    "    collab_recommendations = collaborative_filtering(user_id, user_ratings, n_recommendations)\n",
    "    \n",
    "    hybrid_scores = np.mean([content_recommendations, collab_recommendations], axis=0)\n",
    "    hybrid_recommendations = np.argsort(hybrid_scores)[:n_recommendations]\n",
    "    return hybrid_recommendations\n",
    "\n",
    "print(hybrid_recommendations(0, 0, X_train_tfidf, user_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "Precision: 0.5454545454545454\n",
      "Recall: 0.5660377358490566\n",
      "F1 Score: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "y_true = np.random.randint(0, 2, size=100)\n",
    "y_pred = np.random.randint(0, 2, size=100)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31819, 2970) (7955, 2970) (31819,) (7955,)\n"
     ]
    }
   ],
   "source": [
    "train_indices, test_indices = train_test_split(range(X_train_tfidf.shape[0]), test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_split = X_train_tfidf[train_indices]\n",
    "X_test_split = X_train_tfidf[test_indices]\n",
    "y_train_split = train['cuisine'].iloc[train_indices]\n",
    "y_test_split = train['cuisine'].iloc[test_indices]\n",
    "\n",
    "print(X_train_split.shape, X_test_split.shape, y_train_split.shape, y_test_split.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "#### k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31820, 2970) (7954, 2970) (31820,) (7954,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_tfidf):\n",
    "    X_train_kfold, X_val_kfold = X_train_tfidf[train_index], X_train_tfidf[val_index]\n",
    "    y_train_kfold, y_val_kfold = train['cuisine'].iloc[train_index], train['cuisine'].iloc[val_index]\n",
    "    \n",
    "print(X_train_kfold.shape, X_val_kfold.shape, y_train_kfold.shape, y_val_kfold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Additional Challenges\n",
    "\n",
    "\n",
    "#### Cold-Start Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1030, 1189, 1837, 2321, 1970]\n"
     ]
    }
   ],
   "source": [
    "def recommend_for_new_user(X_tfidf, n_recommendations=5):\n",
    "\n",
    "    mean_tfidf = np.mean(X_tfidf, axis=0)\n",
    "    popular_indices = mean_tfidf.argsort()[0, -n_recommendations:].tolist()[0]\n",
    "    return popular_indices\n",
    "\n",
    "print(recommend_for_new_user(X_train_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For New Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17997  8620  6957 18087 33862]\n"
     ]
    }
   ],
   "source": [
    "def recommend_new_recipe(recipe_ingredients, tfidf, X_tfidf, n_recommendations=5):\n",
    "   \n",
    "    new_recipe_tfidf = tfidf.transform([recipe_ingredients])\n",
    "    \n",
    "    cosine_similarities = cosine_similarity(new_recipe_tfidf, X_tfidf).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-n_recommendations-1:-1]\n",
    "    return related_docs_indices\n",
    "\n",
    "# Example: Recommendations for a new recipe\n",
    "new_recipe_ingredients = \"tomato garlic onion basil\"\n",
    "print(recommend_new_recipe(new_recipe_ingredients, tfidf, X_train_tfidf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
